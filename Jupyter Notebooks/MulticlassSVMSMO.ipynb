{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo code for the SVM SMO algorithm\n",
    "# Algorithm 6.2 SMO with Maximum Violating Pair working set selection\n",
    "# 1:  for all values {1 . . . n} αk  <-- 0 ⊲ Initial coefficients\n",
    "# 2:  for all values {1 . . . n} gk  <-- 1 ⊲ Initial gradient\n",
    "# 3:  loop\n",
    "# 4:  i <-- argmaxi yigi subject to yiαi < Bi\n",
    "# 5:  j <-- argminj yjgj subject to Aj < yjαj ⊲ Maximal violating pair\n",
    "# 6:  if yigi <= yjgj stop. ⊲ Optimality criterion\n",
    "# 7:  λ <- min{ Bi − yiαi, yjαj − Aj , yigi − yjgj Kii + Kjj − 2Kij } ⊲ Direction search\n",
    "# 8:  for all values {1 . . . n} gk <-- gk − λyk Kik + λyk Kjk ⊲ Update gradient\n",
    "# 9:  αi <-- αi + yiλ\n",
    "# 10: αj <-- αj − yjλ ⊲ Update coefficients\n",
    "# 11: end loop\n",
    "\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn import metrics\n",
    "import cffi\n",
    "from pynq import MMIO\n",
    "from pynq import Overlay\n",
    "from pynq import PL\n",
    "import pynq.lib.dma as DMA\n",
    "from time import sleep, time\n",
    "from pynq import Xlnk\n",
    "xlnk = Xlnk()\n",
    "ffi = cffi.FFI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "class_size = 10\n",
    "FEAT = 784\n",
    "\n",
    "# global arrays for support vectors, dual coefficients and estimators per class\n",
    "support_vectors_temp_x = np.empty((class_size), dtype = object)\n",
    "dual_coef_temp = np.empty((class_size), dtype = object)\n",
    "estimators_temp = np.empty((class_size), dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMIO addresses for our accelerator IP core\n",
    "ACCEL_CTRL = 0x43C00000\n",
    "mmult_ip = MMIO(ACCEL_CTRL,0x10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to be able to switch between bitstreams of Kernel function and predict fucntion IPs\n",
    "def bitstream_switcher(flag):    \n",
    "    if(flag == 1):    \n",
    "        global index_dma, input_dma, output_dma\n",
    "        # Download the custom overlay\n",
    "        ol = Overlay(\"accelerator.bit\")\n",
    "        ol.download()\n",
    "\n",
    "        index_dma = ol.axi_dma_0\n",
    "        input_dma = ol.axi_dma_1\n",
    "        output_dma = ol.axi_dma_5        \n",
    "\n",
    "    if(flag == 2):        \n",
    "        global dma1, dma2, dma3, dma4\n",
    "        # Download the custom overlay\n",
    "        ol = Overlay(\"accelerator.bit\")\n",
    "        ol.download()\n",
    "\n",
    "        # Initialize DMA1 (mem to FPGA)\n",
    "        dma1 = ol.axi_dma_2\n",
    "        dma2 = ol.axi_dma_3\n",
    "        dma3 = ol.axi_dma_4\n",
    "        dma4 = ol.axi_dma_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kernels(object):\n",
    "    @staticmethod\n",
    "    def rbf(gamma):\n",
    "        def f(x, y):\n",
    "            exponent = - gamma * np.linalg.norm(x-y) ** 2\n",
    "            return np.exp(exponent)\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardware implementation call of the kernel matrix function\n",
    "def kernel_matrix_hw(input_array,index_array):\n",
    "    global index_dma, input_dma, output_dma\n",
    "    \n",
    "    # determine tile_sizes\n",
    "    remainder = int(input_array.shape[0] % 2500)\n",
    "    iterations = int(input_array.shape[0] / 2500)\n",
    "        \n",
    "    # final output array after batch processing\n",
    "    output_array = np.empty((input_array.shape[0]), dtype=np.float32)\n",
    "    \n",
    "    # after determining number of batch iterations needed, loopcounter as loop variable.\n",
    "    for loopcounter in range(iterations):\n",
    "        # can handle only 2500 values at a time, so 2500 * 4 + 10000\n",
    "        length_x = 2500\n",
    "        tile_size = int(length_x / 100)\n",
    "        remaining_size = length_x % 100  \n",
    "        in_buffer_index = xlnk.cma_array(shape=(FEAT), dtype=np.float32)\n",
    "        in_buffer_kernel = xlnk.cma_array(shape=(length_x*FEAT), dtype=np.float32)  \n",
    "        out_buffer_kernel = xlnk.cma_array(shape=(length_x), dtype=np.float32)  \n",
    "        \n",
    "        # instantiate pre written values to the IPs registers before accelerator call\n",
    "        mmult_ip.write(0x10, 1) # function flag\n",
    "        mmult_ip.write(0x18, length_x) # number of samples\n",
    "        mmult_ip.write(0x20, tile_size) # tile size \n",
    "        mmult_ip.write(0x28, remaining_size) # remaining tile size\n",
    "\n",
    "        ctrl=mmult_ip.read(0x00)&0x08 # Start the accelerator\n",
    "        mmult_ip.write(0x00, (ctrl|0x81))\n",
    "        \n",
    "        # move values to memory buffer for DMa transfer\n",
    "        ffi.memmove(in_buffer_index, ffi.cast(\"uint32_t *\", index_array.ctypes.data), FEAT*4)\n",
    "        ffi.memmove(in_buffer_kernel, ffi.cast(\"uint32_t *\", input_array[loopcounter*2500 : ((loopcounter+1)*2500)].ctypes.data), length_x*FEAT*4)\n",
    "        \n",
    "        # transfer values to DMA buffer\n",
    "        index_dma.sendchannel.transfer(in_buffer_index)\n",
    "        input_dma.sendchannel.transfer(in_buffer_kernel)\n",
    "        output_dma.recvchannel.transfer(out_buffer_kernel)\n",
    "        \n",
    "        # handshake signals to determine completion of DMA send and receives\n",
    "        index_dma.sendchannel.wait()\n",
    "        input_dma.sendchannel.wait()\n",
    "        output_dma.recvchannel.wait()\n",
    "        \n",
    "        # clean allocated buffers and connections between DMA and kernel after transaction complete\n",
    "        in_buffer_index.close()\n",
    "        in_buffer_kernel.close()\n",
    "        out_buffer_kernel.close()\n",
    "        \n",
    "        output_array[loopcounter*2500 : ((loopcounter+1)*2500)] = out_buffer_kernel;\n",
    "    \n",
    "    # for the remaining number of values that might not be a value of mod 2500\n",
    "    if(remainder > 0):\n",
    "        length_x = remainder\n",
    "        tile_size = int(length_x / 100)\n",
    "        remaining_size = length_x % 100  \n",
    "        \n",
    "        in_buffer_index = xlnk.cma_array(shape=(FEAT), dtype=np.float32)\n",
    "        in_buffer_kernel = xlnk.cma_array(shape=(length_x*FEAT), dtype=np.float32)  \n",
    "        out_buffer_kernel = xlnk.cma_array(shape=(length_x), dtype=np.float32)  \n",
    "\n",
    "        mmult_ip.write(0x10, 1) # function flag\n",
    "        mmult_ip.write(0x18, length_x) # number of samples\n",
    "        mmult_ip.write(0x20, tile_size) # tile size \n",
    "        mmult_ip.write(0x28, remaining_size) # remaining tile size\n",
    "\n",
    "        ctrl=mmult_ip.read(0x00)&0x08 # Start the accelerator\n",
    "        mmult_ip.write(0x00, (ctrl|0x81))\n",
    "\n",
    "        ffi.memmove(in_buffer_index, ffi.cast(\"uint32_t *\", index_array.ctypes.data), FEAT*4)\n",
    "        ffi.memmove(in_buffer_kernel, ffi.cast(\"uint32_t *\", input_array[(input_array.shape[0] - remainder) : (input_array.shape[0])].ctypes.data), length_x*FEAT*4)\n",
    "\n",
    "        index_dma.sendchannel.transfer(in_buffer_index)\n",
    "        input_dma.sendchannel.transfer(in_buffer_kernel)\n",
    "        output_dma.recvchannel.transfer(out_buffer_kernel)\n",
    "\n",
    "        index_dma.sendchannel.wait()\n",
    "        input_dma.sendchannel.wait()\n",
    "        output_dma.recvchannel.wait()\n",
    "\n",
    "        in_buffer_index.close()\n",
    "        in_buffer_kernel.close()\n",
    "        out_buffer_kernel.close()\n",
    "        \n",
    "        output_array[(input_array.shape[0] - remainder) : (input_array.shape[0])] = out_buffer_kernel; \n",
    "        \n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_function_hw(input_array1, input_array2, input_array3):\n",
    "    global dma1, dma2, dma3, dma4\n",
    "    \n",
    "    iterations_predict = int(input_array1.shape[0] / 100)\n",
    "    remainder_predict = int(input_array1.shape[0] % 100)\n",
    "    \n",
    "    output_array_predict = np.empty((input_array1.shape[0]), dtype=np.float32)\n",
    "    \n",
    "    for loopcounter_predict in range(iterations_predict):\n",
    "        length_x = 100\n",
    "        length_dc = input_array3.shape[0]\n",
    "        \n",
    "        in_buffer1 = xlnk.cma_array(shape=(length_x*FEAT), dtype=np.float32)\n",
    "        in_buffer2 = xlnk.cma_array(shape=(length_dc*FEAT), dtype=np.float32)\n",
    "        in_buffer3 = xlnk.cma_array(shape=(length_dc), dtype=np.float32)\n",
    "        out_buffer = xlnk.cma_array(shape=(length_x), dtype=np.float32)\n",
    "        \n",
    "        tile_count = int(input_array2.shape[0] / 20);\n",
    "        remaining = input_array2.shape[0] % 20;\n",
    "        \n",
    "        mmult_ip.write(0x10, 2) # function flag\n",
    "        mmult_ip.write(0x30, tile_count)\n",
    "        mmult_ip.write(0x38, remaining)\n",
    "        mmult_ip.write(0x40, length_dc)\n",
    "        \n",
    "         # Start the accelerator\n",
    "        ctrl=mmult_ip.read(0x00)&0x08\n",
    "        mmult_ip.write(0x00, (ctrl|0x81))\n",
    "        \n",
    "        ffi.memmove(in_buffer1, ffi.cast(\"uint32_t *\", input_array1[(loopcounter_predict * 100) : ((loopcounter_predict + 1)*100)-1].ctypes.data), length_x*FEAT*4)\n",
    "        ffi.memmove(in_buffer2, ffi.cast(\"uint32_t *\", input_array2.ctypes.data), length_dc*FEAT*4)\n",
    "        ffi.memmove(in_buffer3, ffi.cast(\"uint32_t *\", input_array3.ctypes.data), length_dc*4)\n",
    "        \n",
    "        dma1.sendchannel.transfer(in_buffer1)\n",
    "        dma2.sendchannel.transfer(in_buffer2)\n",
    "        dma3.sendchannel.transfer(in_buffer3)\n",
    "\n",
    "        dma4.recvchannel.transfer(out_buffer)\n",
    "        dma1.sendchannel.wait()\n",
    "        dma2.sendchannel.wait()\n",
    "        dma3.sendchannel.wait()\n",
    "        dma4.recvchannel.wait()\n",
    "\n",
    "        in_buffer1.close()\n",
    "        in_buffer2.close()\n",
    "        in_buffer3.close()\n",
    "        out_buffer.close()\n",
    "        \n",
    "        output_array_predict[loopcounter_predict*100 : ((loopcounter_predict+1)*100)] = out_buffer;\n",
    "        \n",
    "    if(remainder_predict > 0):\n",
    "        length_x = remainder_predict\n",
    "        length_dc = input_array3.shape[0]\n",
    "        \n",
    "        in_buffer1 = xlnk.cma_array(shape=(length_x*FEAT), dtype=np.float32)\n",
    "        in_buffer2 = xlnk.cma_array(shape=(length_dc*FEAT), dtype=np.float32)\n",
    "        in_buffer3 = xlnk.cma_array(shape=(length_dc), dtype=np.float32)\n",
    "        out_buffer = xlnk.cma_array(shape=(length_x), dtype=np.float32)\n",
    "        \n",
    "        mmult_ip.write(0x10, 2) # function flag\n",
    "        mmult_ip.write(0x30, tile_count)\n",
    "        mmult_ip.write(0x38, remaining)\n",
    "        mmult_ip.write(0x40, length_dc)\n",
    "        \n",
    "         # Start the accelerator\n",
    "        ctrl=mmult_ip.read(0x00)&0x08\n",
    "        mmult_ip.write(0x00, (ctrl|0x81))\n",
    "        \n",
    "        ffi.memmove(in_buffer1, ffi.cast(\"uint32_t *\", input_array1[(input_array1.shape[0] - remainder_predict) : input_array1.shape[0]].ctypes.data), length_x*FEAT*4)\n",
    "        ffi.memmove(in_buffer2, ffi.cast(\"uint32_t *\", input_array2.ctypes.data), length_dc*FEAT*4)\n",
    "        ffi.memmove(in_buffer3, ffi.cast(\"uint32_t *\", input_array3.ctypes.data), length_dc*4)\n",
    "        \n",
    "        dma1.sendchannel.transfer(in_buffer1)\n",
    "        dma2.sendchannel.transfer(in_buffer2)\n",
    "        dma3.sendchannel.transfer(in_buffer3)\n",
    "\n",
    "        dma4.recvchannel.transfer(out_buffer)\n",
    "        dma1.sendchannel.wait()\n",
    "        dma2.sendchannel.wait()\n",
    "        dma3.sendchannel.wait()\n",
    "        dma4.recvchannel.wait()\n",
    "\n",
    "        in_buffer1.close()\n",
    "        in_buffer2.close()\n",
    "        in_buffer3.close()\n",
    "        out_buffer.close()\n",
    "        \n",
    "        output_array_predict[(output_array_predict.shape[0] - remainder_predict) : output_array_predict.shape[0]] = out_buffer;\n",
    "\n",
    "    return output_array_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binary_svm(object):\n",
    "    def __init__(self, kernel, tol, C, support_vector_tol = 0.0, max_iter = 1000):\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.support_vector_indices = 0.0\n",
    "        self.support_vectors = []\n",
    "        self.dual_coef = []\n",
    "        self.support_vector_tol = support_vector_tol\n",
    "\n",
    "    def kernel_matrix(self, X, index):\n",
    "        result = np.zeros(X.shape[0])\n",
    "        x_i = X[index, :]\n",
    "        for j, x_j in enumerate(X):\n",
    "            result[j] = self.kernel(x_i, x_j)\n",
    "        return result\n",
    "\n",
    "    def smo(self, X, y):\n",
    "        iterations = 0\n",
    "        n_samples = X.shape[0]\n",
    "        # Initial coefficients\n",
    "        alpha = np.zeros(n_samples)\n",
    "        # Initial gradient\n",
    "        g = np.ones(n_samples)\n",
    "        while True:\n",
    "            yg = g * y\n",
    "            # KKT Conditions\n",
    "            y_pos_ind = (y == 1)\n",
    "            y_neg_ind = (np.ones(n_samples) - y_pos_ind).astype(bool)\n",
    "            alpha_pos_ind = (alpha >= self.C)\n",
    "            alpha_neg_ind = (alpha <= 0)\n",
    "\n",
    "            indices_violating_Bi_1 = y_pos_ind * alpha_pos_ind\n",
    "            indices_violating_Bi_2 = y_neg_ind * alpha_neg_ind\n",
    "            indices_violating_Bi = indices_violating_Bi_1 + indices_violating_Bi_2\n",
    "            yg_i = yg.copy()\n",
    "            yg_i[indices_violating_Bi] = float('-inf')\n",
    "            # First of the maximum violating pair\n",
    "            i = np.argmax(yg_i)\n",
    "#             Kik = self.kernel_matrix(X, i)\n",
    "            Kik = kernel_matrix_hw(X.astype(np.float32), X[i].astype(np.float32))\n",
    "\n",
    "            indices_violating_Ai_1 = y_pos_ind * alpha_neg_ind\n",
    "            indices_violating_Ai_2 = y_neg_ind * alpha_pos_ind\n",
    "            indices_violating_Ai = indices_violating_Ai_1 + indices_violating_Ai_2\n",
    "            yg_j = yg.copy()\n",
    "            yg_j[indices_violating_Ai] = float('+inf')\n",
    "            # Second of the maximum violating pair\n",
    "            j = np.argmin(yg_j)\n",
    "#             Kjk = self.kernel_matrix(X, j)\n",
    "            Kjk = kernel_matrix_hw(X.astype(np.float32), X[j].astype(np.float32))\n",
    "\n",
    "            # Optimality criterion\n",
    "            if(yg_i[i] - yg_j[j]) < self.tol or (iterations >= self.max_iter):\n",
    "                break\n",
    "\n",
    "            min_term_1 = (y[i] == 1) * self.C - y[i] * alpha[i]\n",
    "            min_term_2 = y[j] * alpha[j] + (y[j] == -1) * self.C\n",
    "            min_term_3 = (yg_i[i] - yg_j[j]) / (Kik[i] + Kjk[j] - 2 * Kik[j])\n",
    "\n",
    "            # Direction search\n",
    "            lamda = np.min([min_term_1, min_term_2, min_term_3])\n",
    "            # Gradient update\n",
    "            g += lamda * y * (Kjk - Kik)\n",
    "            # Update coefficients\n",
    "            alpha[i] = alpha[i] + y[i] * lamda\n",
    "            alpha[j] = alpha[j] - y[j] * lamda\n",
    "\n",
    "            iterations += 1\n",
    "\n",
    "        print('{} iterations to arrive at the minimum'.format(iterations))\n",
    "        return alpha\n",
    "\n",
    "    def train(self, X, y, label, batch_number):\n",
    "        global support_vectors_temp_x, dual_coef_temp\n",
    "        lagrange_multipliers = self.smo(X, y)\n",
    "        self.support_vector_indices = lagrange_multipliers > self.support_vector_tol\n",
    "        self.dual_coef = lagrange_multipliers[self.support_vector_indices] * y[self.support_vector_indices]\n",
    "        self.support_vectors = X[self.support_vector_indices]\n",
    "\n",
    "        if(batch_number == 0):\n",
    "            support_vectors_temp_x[label] = self.support_vectors\n",
    "            dual_coef_temp[label] = self.dual_coef\n",
    "            print('{} Support Vectors'.format(self.support_vectors.shape[0]))\n",
    "\n",
    "        if(batch_number != 0):\n",
    "            print('{} Support Vectors'.format(self.support_vectors.shape[0]))\n",
    "            self.support_vectors = np.row_stack((self.support_vectors, support_vectors_temp_x[label]))\n",
    "            self.dual_coef = np.concatenate((self.dual_coef, dual_coef_temp[label]))\n",
    "            support_vectors_temp_x[label] = self.support_vectors\n",
    "            dual_coef_temp[label] = self.dual_coef\n",
    "            print('{} Updated Support Vectors'.format(self.support_vectors.shape[0]))\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        prediction = np.zeros(n_samples)\n",
    "        for i, x in enumerate(X):\n",
    "            result = 0.0\n",
    "            for z_i, x_i in zip(self.dual_coef, self.support_vectors):\n",
    "                result += z_i * self.kernel(x_i, x)\n",
    "            prediction[i] = result\n",
    "        return prediction\n",
    "    \n",
    "    def predict_hw(self, X):\n",
    "        prediction = predict_function_hw(X.astype(np.float32), self.support_vectors.astype(np.float32), self.dual_coef.astype(np.float32))\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiclass(object):\n",
    "    def __init__(self, kernel, tol, C, max_iter = 1000):\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.indices = []\n",
    "    \n",
    "    # for use in the binarz SVM function\n",
    "    def binarize_labels(self, X, y, label):\n",
    "        pos_class_indices = (y == label)\n",
    "        neg_class_indices = (y != label)\n",
    "        X_binarized = X.copy()\n",
    "        y_binarized = y.copy()\n",
    "        y_binarized[pos_class_indices] = +1\n",
    "        y_binarized[neg_class_indices] = -1\n",
    "        return X_binarized, y_binarized\n",
    "\n",
    "    def train(self, X, y, batch_number):\n",
    "        global estimators_temp\n",
    "        self.classes = set(y)\n",
    "        classifiers = np.empty(len(self.classes), dtype = object)\n",
    "\n",
    "        for i, label in enumerate(self.classes):\n",
    "            print(\"Label: {}\".format(label))\n",
    "            svm_binary = binary_svm(kernel = self.kernel, C = self.C, max_iter = self.max_iter, tol = self.tol)\n",
    "            X_binarized, y_binarized = self.binarize_labels(X, y, i)\n",
    "            svm_binary.train(X_binarized, y_binarized, int(label), batch_number)\n",
    "            classifiers[i] = svm_binary\n",
    "            estimators_temp[int(label)] = classifiers[i]\n",
    "            classifiers[i] = estimators_temp[int(label)]\n",
    "        self.estimators = estimators_temp\n",
    "\n",
    "    def predict(self, X, input):\n",
    "        classes = set(input)\n",
    "        n_samples = X.shape[0]\n",
    "        predicted_scores = np.zeros((n_samples, len(classes)))\n",
    "        for i, label in enumerate(classes):\n",
    "            print(\"Predicting label: {}\".format(i))\n",
    "#             predicted_scores[:,i] = self.estimators[i].predict(X)\n",
    "            predicted_scores[:,i] = self.estimators[i].predict_hw(X)\n",
    "\n",
    "        return np.argmax(predicted_scores, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":   \n",
    "    \n",
    "    classifier = multiclass(C = 10.0, kernel=kernels.rbf(0.05), tol = 2.0)\n",
    "    start_time = dt.datetime.now()\n",
    "    print('Start learning at: {}'.format(str(start_time)))\n",
    "\n",
    "    for batch_number in range(batch_size):\n",
    "        print('\\nBatch number: {}'.format(batch_number))\n",
    "        if(batch_number == 0):\n",
    "            bitstream_switcher(1)\n",
    "            X_train_batch = np.load('data/X_train_batch_{}.npy'.format(batch_number))\n",
    "            y_train_batch = np.load('data/y_train_batch_{}.npy'.format(batch_number))\n",
    "            classifier.train(X_train_batch, y_train_batch, batch_number)\n",
    "            print(X_train_batch.shape, y_train_batch.shape)\n",
    "        if(batch_number != 0):\n",
    "            bitstream_switcher(2)            \n",
    "            X_train_batch = np.load('data/X_train_batch_{}.npy'.format(batch_number))\n",
    "            y_train_batch = np.load('data/y_train_batch_{}.npy'.format(batch_number))\n",
    "            predicted = classifier.predict(X_train_batch, y_train_batch)\n",
    "            bitstream_switcher(1) \n",
    "            expected = y_train_batch\n",
    "            m = expected != predicted\n",
    "            print('Misclassified samples: {}'.format(X_train_batch[m].shape[0]))\n",
    "            classifier.train(X_train_batch[m], y_train_batch[m], batch_number)\n",
    "            print(X_train_batch.shape, y_train_batch.shape)\n",
    "    end_time = dt.datetime.now()\n",
    "    print('Stop learning {}'.format(str(end_time)))\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Elapsed learning time: {}'.format(str(elapsed_time)))\n",
    "\n",
    "    X_test = np.load('data/X_test.npy')\n",
    "    y_test = np.load('data/y_test.npy')\n",
    "    expected = y_test\n",
    "    start_time = dt.datetime.now()\n",
    "    print('Start predicting at: {}'.format(str(start_time)))\n",
    "    predicted = classifier.predict(X_test, np.arange(estimators_temp.shape[0]))\n",
    "    end_time = dt.datetime.now()\n",
    "    print('Stop predicting: {}'.format(str(end_time)))\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Elapsed predicting time: {}'.format(str(elapsed_time)))\n",
    "\n",
    "    print(\"Classification report:\\n%s\\n\" % (metrics.classification_report(expected, predicted)))\n",
    "    cm = metrics.confusion_matrix(expected, predicted)\n",
    "    print(\"Confusion matrix:\\n%s\" % cm)\n",
    "    print(\"Accuracy: {}\".format(metrics.accuracy_score(expected, predicted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
